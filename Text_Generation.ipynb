{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import requests\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of treasure island, by robert louis stevenson\n",
      "\n",
      "this ebook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  you may copy it, give it away or\n",
      "re-use it under the terms of the project gutenberg license included\n",
      "with this ebook or online at www.gutenberg.net\n",
      "\n",
      "\n",
      "title: treasure island\n",
      "\n",
      "author: robert louis stevenson\n",
      "\n",
      "illustrator: milo winter\n",
      "\n",
      "release date: january 12, 2009 [ebook #27780]\n",
      "\n",
      "language: english\n",
      "\n",
      "\n",
      "*** start of this project gutenberg ebook treasure island ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "produced by juliet sutherland, stephen blundell and the\n",
      "online distributed proofreading team at http://www.pgdp.net\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the illustrated children's library\n",
      "\n",
      "\n",
      "         _treasure island_\n",
      "\n",
      "       robert louis stevenson\n",
      "\n",
      "          _illustrated by_\n",
      "            milo winter\n",
      "\n",
      "\n",
      "           [illustration]\n",
      "\n",
      "\n",
      "           gramercy books\n",
      "              new york\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " foreword copyright Â© 1986 by random house value publishing\n",
      " color illustrations by milo winter copyrig\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"Text.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "print(raw_text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = raw_text.lower()\n",
    "processed_text = re.sub(r'[^\\x00-\\x7f]',r'', processed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(processed_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  389308\n",
      "Total Vocab:  59\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(processed_text)\n",
    "n_vocab = len(chars)\n",
    "print( \"Total Characters: \", n_chars)\n",
    "print( \"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  389208\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = processed_text[i:i + seq_length]\n",
    "\tseq_out = processed_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print( \"Total Patterns: \", n_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "389120/389208 [============================>.] - ETA: 0s - loss: 2.8598Epoch 00000: loss improved from inf to 2.85976, saving model to weights-improvement-00-2.8598.hdf5\n",
      "389208/389208 [==============================] - 1915s - loss: 2.8598  \n",
      "Epoch 2/5\n",
      "389120/389208 [============================>.] - ETA: 0s - loss: 2.6950Epoch 00001: loss improved from 2.85976 to 2.69498, saving model to weights-improvement-01-2.6950.hdf5\n",
      "389208/389208 [==============================] - 1881s - loss: 2.6950  \n",
      "Epoch 3/5\n",
      "389120/389208 [============================>.] - ETA: 0s - loss: 2.6065Epoch 00002: loss improved from 2.69498 to 2.60645, saving model to weights-improvement-02-2.6065.hdf5\n",
      "389208/389208 [==============================] - 1873s - loss: 2.6065  \n",
      "Epoch 4/5\n",
      "389120/389208 [============================>.] - ETA: 0s - loss: 2.5268Epoch 00003: loss improved from 2.60645 to 2.52680, saving model to weights-improvement-03-2.5268.hdf5\n",
      "389208/389208 [==============================] - 1948s - loss: 2.5268  \n",
      "Epoch 5/5\n",
      "389120/389208 [============================>.] - ETA: 0s - loss: 2.4635Epoch 00004: loss improved from 2.52680 to 2.46347, saving model to weights-improvement-04-2.4635.hdf5\n",
      "389208/389208 [==============================] - 2644s - loss: 2.4635  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273dbcdcb70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "#filename = \"weights-improvement-19-2.0368.hdf5\"\n",
    "filename = \"weights-improvement-04-2.4635.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  and well; he was the oldest of our party by a score\n",
      "of years; and now, sullen, old, serviceable ser \"\n",
      " the sore to the tooee of the sooee and the sooee to the tooee th tee soone to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee th tee soine to the tooee t\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print( \"Seed:\")\n",
    "print( \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print( \"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
